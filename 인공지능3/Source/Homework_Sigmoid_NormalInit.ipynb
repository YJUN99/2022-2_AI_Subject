{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Homework.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/1+np.exp(-x)\n",
    "def sigmoid_derv(y):\n",
    "    return sigmoid(y) * (1 - (1/sigmoid(y))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 4\n",
    "# 은닉 계층 하나를 위한 순전파 함수 정의\n",
    "def forward_neuralnet_hidden1(x):\n",
    "    # init_model_hidden1 쌍의 파라미터에 접근\n",
    "    global pm_output, pm_hidden\n",
    "    \n",
    "    #입력 x와 pm_hidden을 통해 은닉계층 출력 계산 Relu함수 사용\n",
    "    hidden = sigmoid(np.matmul(x, pm_hidden['w']) + pm_hidden['b'])\n",
    "    #hidden과 pm_output을 통해 출력계층 출력이자 최종출력 output 계산\n",
    "    output = np.matmul(hidden, pm_output['w']) + pm_output['b']\n",
    "    \n",
    "    #출력 계층의 역전파 처리 때 가중치에 대한 편미분 정보로 hidden이 필요함\n",
    "    return output, [x, hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 4\n",
    "# 은닉 계층 하나를 위한 역전파 함수 정의\n",
    "def backprop_neuralnet_hidden1(G_output, aux):\n",
    "    # G_output은 역전파 후처리 후만들어지는 파라미터\n",
    "    global pm_output, pm_hidden\n",
    "    \n",
    "    # 순전파에 사용됐던 input\n",
    "    x, hidden = aux\n",
    "    \n",
    "    # 출력층에 대한 역전파\n",
    "    # 출력층에서 사용하는 input은 hidden \n",
    "    g_output_w_out = hidden.transpose()                      \n",
    "    G_w_out = np.matmul(g_output_w_out, G_output)            \n",
    "    G_b_out = np.sum(G_output, axis=0)    \n",
    "    \n",
    "    # 출력 계층과 은닉 계층 역전파 처리 매개하는 G_output으로부터 G_hidden을 구해내는 과정\n",
    "    g_output_hidden = pm_output['w'].transpose()\n",
    "    # pm_output['w']은 변환이 되는 계수이기 때문에 미리 기록한 것 위에 명시된 식에서 W_2\n",
    "    G_hidden = np.matmul(G_output, g_output_hidden)   \n",
    "    print(G_w_out)\n",
    "    # 출력층 역전파\n",
    "    pm_output['w'] -= LEARNING_RATE * G_w_out                \n",
    "    pm_output['b'] -= LEARNING_RATE * G_b_out                \n",
    "    \n",
    "    # 은닉층 -> relu -> 출력층 순서\n",
    "    # 역전파는 그 반대로 가야하기 때문에 Relu 부분을 처리해줘야 함 위 식에서 편미분값\n",
    "    G_hidden = G_hidden * sigmoid_derv(hidden)\n",
    "    \n",
    "    # 은닉층에 대한 역전파\n",
    "    # 은닉층에서 사용하는 input은 x\n",
    "    g_hidden_w_hid = x.transpose()\n",
    "    G_w_hid = np.matmul(g_hidden_w_hid, G_hidden)            \n",
    "    G_b_hid = np.sum(G_hidden, axis=0)                       \n",
    "    \n",
    "    # 은닉층 역전파\n",
    "    pm_hidden['w'] -= LEARNING_RATE * G_w_hid                \n",
    "    pm_hidden['b'] -= LEARNING_RATE * G_b_hid                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단층구조 Node : 1 sigmoid\n",
    "LEARNING_RATE = 0.001\n",
    "RND_MEAN = 0\n",
    "RND_STD = 0.0030\n",
    "file_set('[1] _ ETA x 0.1 _ STD  _ sigmoid')\n",
    "file_weight_set('[1] _ ETA x 0.1 _ STD  _ sigmoid _ w')\n",
    "set_hidden([2,2])\n",
    "NUM_exec(epoch_count=1000, report=5)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단층구조 Node : 1 sigmoid\n",
    "LEARNING_RATE = 0.001\n",
    "RND_MEAN = 0\n",
    "RND_STD = 0.0030\n",
    "file_set('[1] _ ETA x 0.1 _ STD  _ sigmoid')\n",
    "file_weight_set('[1] _ ETA x 0.1 _ STD  _ sigmoid _ w')\n",
    "set_hidden([2,2])\n",
    "NUM_exec(epoch_count=1000, report=5)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46cfcddb68c68611b443db1323088e94cb0f2369a1b7d13b2027887d22e53dd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
